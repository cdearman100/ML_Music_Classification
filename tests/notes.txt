## SUBSEQUENT
No dropout, No Batch Normilaztion, 4 Layer
[0.5, 0.5, 0.6666666865348816, 0.8333333134651184]

### NON SUBSEQUENT

## CHange batch size

# Batch size = 8                                                    BEST
[0.3333333432674408, 0.9166666865348816, 0.8333333134651184]
[0.75, 0.75, 0.6666666865348816]
[0.8333333134651184, 0.9166666865348816, 0.75]

# Batch size = 4 
[0.75, 0.6666666865348816, 0.8333333134651184]
[0.6666666865348816, 0.75, 0.4166666567325592]

## Change Dense layer size
# BASE ONLY ONE LAYER: Dense 64, Dense 32                          BEST
[0.75, 0.6666666865348816, 0.8333333134651184]
[0.75, 0.8333333134651184, 0.8333333134651184]

# Lower: Dense 32, Dense 16
[0.8333333134651184, 0.25, 0.4166666567325592]





## Change Features - Epochs = 200
# BASE

Only MFCC + ZCR + Rolloff + Specteral + rms + chroma
[0.6666666865348816, 0.5833333134651184, 0.5]

Only MFCC + ZCR + Rolloff + Specteral + rms 
[0.75, 0.75, 0.75]
[0.5, 0.5, 0.5]

Only MFCC + ZCR + Rolloff + Specteral
[0.5, 0.5833333134651184, 0.75]
[0.6666666865348816, 0.8333333134651184, 0.75]
[0.6666666865348816, 0.8333333134651184, 0.75]

Only MFCC + ZCR + Rolloff
[0.6666666865348816, 0.75, 0.5833333134651184]
[0.6666666865348816, 0.75, 0.5]

Only MFCC + ZCR
[0.75, 0.5, 0.6666666865348816]
[0.4166666567325592, 0.6666666865348816, 0.6666666865348816]


# Only MFCC
[0.5833333134651184, 0.9166666865348816, 0.6666666865348816]
[0.5833333134651184, 0.3333333432674408, 0.6666666865348816]



## Change filter size - Epochs = 200

# BASE
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,3,5,7, batch size= 16
[0.9166666865348816, 0.75, 0.6666666865348816]

# Same High filter val 
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 128,128,128,3,5,7, batch size= 16
[0.75, 0.6666666865348816, 0.75]

# Same Low filter val 
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 32,32,32,3,5,7, batch size= 16
[0.5833333134651184, 0.5833333134651184, 0.5]


# Increasing
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 32,64,128,3,5,7, batch size= 16
[0.5, 0.5833333134651184, 0.4166666567325592]






## Change kernel size - Epochs = 200

# Increasing
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,3,5,7, batch size= 16
[0.8333333134651184, 0.8333333134651184, 0.75]


# Same LOW Kernal val
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,3,3,3, batch size= 16
[0.5, 0.6666666865348816, 0.75]


# Increasing MORE
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,5,7,9, batch size= 16
[0.75, 0.5, 0.4166666567325592]

# BASE
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,2,3,7, batch size= 16
[0.5, 0.5833333134651184, 0.5833333134651184]

# Same High Kernal val
Yes Batch, Yes Max Pooling, Yes dropout, 3 Conv1d Layers, 64,64,64,5,5,5, batch size= 16
[0.5833333134651184, 0.4166666567325592, 0.5833333134651184]